{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook helps to prepare the dataset consumed by the E2C model. The data source for this notebook comes from the output of simulation software. In this case, we use AD-GPRS from Stanford ERE department.\n",
    "\n",
    "## Instructions for the datasets:\n",
    "\n",
    "### File name codes:\n",
    "`_norm_bhps`: dataset for normalized BHPs  \n",
    "`_train`: dataset for pressure (normalized) and saturation  \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Load libraries and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.set_cmap('jet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load pressure and saturation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../data/'\n",
    "case_name = '9w_ms_bhp_rate'\n",
    "state_file = case_name + '_train_n_400_full'\n",
    "ctrl_file = case_name + '_norm_bhps_n_400'\n",
    "case_suffix = '_fix_wl_rel_8'\n",
    "train_suffix = '_with_p'\n",
    "\n",
    "state_data = state_file + case_suffix + '.mat'\n",
    "ctrl_data = ctrl_file + case_suffix + '.mat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_r = h5py.File(data_dir + state_data, 'r')\n",
    "sat = np.array(hf_r.get('sat'))\n",
    "pres = np.array(hf_r.get('pres'))\n",
    "hf_r.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sat = sat.T.reshape((400, 201, 3600))\n",
    "pres = pres.T.reshape(400,201,3600)\n",
    "print(\"sat shape:{}\".format(sat.shape))\n",
    "print(\"pres shape:{}\".format(pres.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dt = 10 # timestep, not days\n",
    "days_per_step = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Visualization of pressure and saturation data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saturation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for k in range(4):\n",
    "    i_case = 100*k+1\n",
    "    plt.figure(figsize=(16,6))\n",
    "    print(\"case number: %d\"%(i_case))\n",
    "    for idx in range(5):\n",
    "        plt.subplot(2,5, idx+1)\n",
    "        plt.imshow(sat[i_case, idx*4, :].reshape((60,60)))\n",
    "        plt.title(\"t=%d days\"%(idx*4*days_per_step))\n",
    "    for idx in range(5):\n",
    "        plt.subplot(2,5, idx+6)\n",
    "        plt.imshow(sat[i_case, idx*40+20, :].reshape((60,60)))\n",
    "        plt.title(\"t=%d days\"%((idx*40+20)*days_per_step))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pressure data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for k in range(4):\n",
    "    i_case = 100*k+1\n",
    "    plt.figure(figsize=(16,6))\n",
    "    print(\"case number: %d\"%(i_case))\n",
    "    for idx in range(5):\n",
    "        plt.subplot(2,5, idx+1)\n",
    "        plt.imshow(pres[i_case, idx*4, :].reshape((60,60)))\n",
    "        plt.title(\"t=%d days\"%(idx*4*days_per_step))\n",
    "        plt.colorbar(fraction=0.046)\n",
    "        \n",
    "    for idx in range(5):\n",
    "        plt.subplot(2,5, idx+6)\n",
    "        plt.imshow(pres[i_case, idx*40+20, :].reshape((60,60)))\n",
    "        plt.title(\"t=%d days\"%((idx*40+20)*days_per_step))\n",
    "        plt.colorbar(fraction=0.046)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some pressure data over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=[1220, 1240, 2420, 2440]\n",
    "\n",
    "plt.figure(figsize=(16,4))\n",
    "for i in range(4):\n",
    "    plt.subplot(1,4,i+1)\n",
    "    plt.plot(range(201), pres[101,:,k[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some saturation data over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=[1220, 1240, 2420, 2440]\n",
    "\n",
    "plt.figure(figsize=(16,4))\n",
    "for i in range(4):\n",
    "    plt.subplot(1,4,i+1)\n",
    "    plt.plot(range(201), sat[101,:,k[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Config timesteps  \n",
    "Constant dt, use the following block (varying dt TBD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = 10 # time step increment, not days\n",
    "t_interval = 10 # not used, days\n",
    "\n",
    "indt = np.array(range(0,200,dt))\n",
    "indt1 = indt + dt\n",
    "# print(indt)\n",
    "# print(indt1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sat_t = sat[:, indt,:]\n",
    "sat_t1 = sat[:, indt1, :]\n",
    "\n",
    "pres_t = pres[:, indt,:]\n",
    "pres_t1 = pres[:, indt1,:]\n",
    "\n",
    "# we need a delta t\n",
    "indt_del = indt1 - indt\n",
    "# print(indt_del)\n",
    "\n",
    "indt_del = indt_del / max(indt_del)\n",
    "# print(indt_del)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_t = sat_t.shape[1]\n",
    "num_case = sat_t.shape[0]\n",
    "\n",
    "print(\"num_t:%d\"%num_t)\n",
    "print(\"num_case:%d\"%num_case)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Read and process control data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_prod = 5\n",
    "num_inj = 4\n",
    "num_well = num_prod + num_inj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_r = h5py.File(data_dir + ctrl_data)\n",
    "bhp0 = np.array(hf_r.get('bhp'))\n",
    "rate0 = np.array(hf_r.get('rate'))\n",
    "hf_r.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_ctrl = bhp0.shape[1] // num_prod\n",
    "assert bhp0.shape[1] // num_prod == rate0.shape[1] // num_inj, \"num_ctrl error!\"\n",
    "# print(num_ctrl)\n",
    "\n",
    "bhp = np.concatenate((bhp0,rate0),axis=1)\n",
    "# print(bhp.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manipulate control data shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with 2 bhps per period\n",
    "num_step = len(indt)\n",
    "print(num_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bhp_b0 = bhp.reshape(num_case, num_well, num_ctrl)\n",
    "bhp_b1 = np.repeat(bhp_b0[..., np.newaxis], num_step // num_ctrl, axis=3)\n",
    "assert num_step // num_ctrl * num_ctrl == num_step, \"no exaxt division num_step = %d, num_ctrl=%d\"%(num_step, num_ctrl)\n",
    "\n",
    "# print(bhp_b1.shape)\n",
    "bhp_b2 = bhp_b1.reshape(num_case, num_well, num_step)\n",
    "# print(bhp_b2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = np.array(range(num_step)) - 1\n",
    "tmp1 = np.array(range(num_step))\n",
    "tmp[0] = 0\n",
    "\n",
    "\n",
    "bhp_tt = bhp_b2[:,:, tmp]\n",
    "bhp_tt1 = bhp_b2[:,:, tmp1]\n",
    "\n",
    "bhp_tt0 = np.concatenate((bhp_tt, bhp_tt1), axis=1)\n",
    "bhp_t = np.swapaxes(bhp_tt0,1,2)\n",
    "\n",
    "\n",
    "n_ctrl = bhp_t.shape[2]\n",
    "print(n_ctrl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extend dimension of delta_t\n",
    "# print(indt_del.shape)\n",
    "indt_dd = np.repeat(indt_del[np.newaxis,:], num_case, axis = 0)\n",
    "indt_d = indt_dd[:,:,np.newaxis]\n",
    "# print(indt_d.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pick a fraction of non-changing control periods, and all changing control periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(bhp_t[0, 15, [0,9]])\n",
    "slt_col = np.array((range(0, 100, 5)))\n",
    "# print(slt_col)\n",
    "\n",
    "np.random.seed(1047)\n",
    "slt_col_2 = np.random.randint(1,5,size=20) + slt_col\n",
    "# print(slt_col_2- slt_col)\n",
    "\n",
    "slt_cols = np.sort(np.concatenate((slt_col, slt_col_2), axis=0))\n",
    "# print(slt_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If choose not to pick column, run the following one block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slt_cols = np.array((range(num_t)))\n",
    "# print(slt_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_t_slt = slt_cols.shape[0]\n",
    "\n",
    "sat_t_slt = sat_t[:,slt_cols,:]\n",
    "sat_t1_slt = sat_t1[:,slt_cols,:]\n",
    "pres_t_slt = pres_t[:,slt_cols,:]\n",
    "pres_t1_slt = pres_t1[:,slt_cols,:]\n",
    "bhp_t_slt = bhp_t[:,slt_cols,:]\n",
    "indt_d_slt = indt_d[:,slt_cols,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4. Train/test set split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_run_per_case = 75\n",
    "sat_t_train = np.zeros((num_run_per_case*4, num_t_slt, 3600))\n",
    "sat_t1_train = np.zeros((num_run_per_case*4, num_t_slt, 3600))\n",
    "bhp_train = np.zeros((num_run_per_case*4, num_t_slt, n_ctrl))\n",
    "dt_train = np.zeros((num_run_per_case*4, num_t_slt, 1))\n",
    "\n",
    "pres_t_train = np.zeros((num_run_per_case*4, num_t_slt, 3600))\n",
    "pres_t1_train = np.zeros((num_run_per_case*4, num_t_slt, 3600))\n",
    "\n",
    "\n",
    "num_run_eval = 100 - num_run_per_case # 25 cases\n",
    "sat_t_eval = np.zeros((num_run_eval*4, num_t_slt, 3600))\n",
    "sat_t1_eval = np.zeros((num_run_eval*4, num_t_slt, 3600))\n",
    "\n",
    "bhp_eval = np.zeros((num_run_eval*4, num_t_slt, n_ctrl))\n",
    "dt_eval = np.zeros((num_run_eval*4, num_t_slt, 1))\n",
    "\n",
    "pres_t_eval = np.zeros((num_run_eval*4, num_t_slt, 3600))\n",
    "pres_t1_eval = np.zeros((num_run_eval*4, num_t_slt, 3600))\n",
    "\n",
    "\n",
    "for k in range(4):\n",
    "    ind0 = k * num_run_per_case\n",
    "    sat_t_train[ind0:ind0+num_run_per_case,...] = sat_t_slt[k*100:k*100+num_run_per_case, :, :]\n",
    "    sat_t1_train[ind0:ind0+num_run_per_case,...] = sat_t1_slt[k*100:k*100+num_run_per_case, :, :]\n",
    "    pres_t_train[ind0:ind0+num_run_per_case,...] = pres_t_slt[k*100:k*100+num_run_per_case, :, :]\n",
    "    pres_t1_train[ind0:ind0+num_run_per_case,...] = pres_t1_slt[k*100:k*100+num_run_per_case, :, :]\n",
    "    bhp_train[ind0:ind0+num_run_per_case,...] = bhp_t_slt[k*100: k*100+num_run_per_case, :, :]\n",
    "    dt_train[ind0:ind0+num_run_per_case,...] = indt_d_slt[k*100: k*100+num_run_per_case, :, :]\n",
    "    # Eval set\n",
    "    ind1 = k*num_run_eval\n",
    "    sat_t_eval[ind1:ind1+num_run_eval,...] = sat_t_slt[k*100+num_run_per_case:k*100+100, :, :]\n",
    "    sat_t1_eval[ind1:ind1+num_run_eval,...] = sat_t1_slt[k*100+num_run_per_case:k*100+100, :, :]\n",
    "    pres_t_eval[ind1:ind1+num_run_eval,...] = pres_t_slt[k*100+num_run_per_case:k*100+100, :, :]\n",
    "    pres_t1_eval[ind1:ind1+num_run_eval,...] = pres_t1_slt[k*100+num_run_per_case:k*100+100, :, :]\n",
    "    bhp_eval[ind1:ind1+num_run_eval,...] = bhp_t_slt[k*100+num_run_per_case: k*100+100, :, :]\n",
    "    dt_eval[ind1:ind1+num_run_eval,...] = indt_d_slt[k*100+num_run_per_case: k*100+100, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train_run = sat_t_train.shape[0]\n",
    "n_eval_run = sat_t_eval.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sat_t_train = sat_t_train.reshape((num_run_per_case*4*num_t_slt, 60, 60, 1))\n",
    "sat_t1_train = sat_t1_train.reshape((num_run_per_case*4*num_t_slt, 60, 60, 1))\n",
    "pres_t_train = pres_t_train.reshape((num_run_per_case*4*num_t_slt, 60, 60, 1))\n",
    "pres_t1_train = pres_t1_train.reshape((num_run_per_case*4*num_t_slt, 60, 60, 1))\n",
    "bhp_train = bhp_train.reshape((num_run_per_case*4*num_t_slt, n_ctrl))\n",
    "dt_train = dt_train.reshape((num_run_per_case*4*num_t_slt, 1))\n",
    "# Eval\n",
    "sat_t_eval = sat_t_eval.reshape((num_run_eval*4*num_t_slt, 60, 60, 1))\n",
    "sat_t1_eval = sat_t1_eval.reshape((num_run_eval*4*num_t_slt, 60, 60, 1))\n",
    "pres_t_eval = pres_t_eval.reshape((num_run_eval*4*num_t_slt, 60, 60, 1))\n",
    "pres_t1_eval = pres_t1_eval.reshape((num_run_eval*4*num_t_slt, 60, 60, 1))\n",
    "bhp_eval = bhp_eval.reshape((num_run_eval*4*num_t_slt, n_ctrl))\n",
    "dt_eval = dt_eval.reshape((num_run_eval*4*num_t_slt, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train_step = sat_t_train.shape[0]\n",
    "n_eval_step = sat_t_eval.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_t_train = np.concatenate((sat_t_train, pres_t_train),axis=3)\n",
    "state_t1_train = np.concatenate((sat_t1_train, pres_t1_train),axis=3)\n",
    "\n",
    "state_t_eval = np.concatenate((sat_t_eval, pres_t_eval),axis=3)\n",
    "state_t1_eval = np.concatenate((sat_t1_eval, pres_t1_eval),axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = num_run_per_case*4*num_t_slt\n",
    "shuffle_ind_train = np.random.permutation(num_train)\n",
    "state_t_train = state_t_train[shuffle_ind_train, ...]\n",
    "state_t1_train = state_t1_train[shuffle_ind_train, ...]\n",
    "bhp_train = bhp_train[shuffle_ind_train, ...]\n",
    "dt_train = dt_train[shuffle_ind_train, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_eval = num_run_eval*4*num_t_slt\n",
    "shuffle_ind_eval = np.random.permutation(num_eval)\n",
    "state_t_eval = state_t_eval[shuffle_ind_eval, ...]\n",
    "state_t1_eval = state_t1_eval[shuffle_ind_eval, ...]\n",
    "bhp_eval = bhp_eval[shuffle_ind_eval, ...]\n",
    "dt_eval = dt_eval[shuffle_ind_eval, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select subset of training\n",
    "n_train_step = 6000\n",
    "state_t_train = state_t_train[:n_train_step, ...]\n",
    "state_t1_train = state_t1_train[:n_train_step, ...]\n",
    "bhp_train = bhp_train[:n_train_step, ...]\n",
    "dt_train = dt_train[:n_train_step, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dt_train.shape)\n",
    "dt = 100 # days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5. Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_w = h5py.File(data_dir + case_name + '_e2c_train' + case_suffix + train_suffix+ '_n%d_dt%dday_nt%d_nrun%d.mat' %(n_train_step, dt, num_t_slt, n_train_run), 'w')\n",
    "hf_w.create_dataset('state_t', data=state_t_train)\n",
    "hf_w.create_dataset('state_t1', data=state_t1_train)\n",
    "hf_w.create_dataset('bhp', data = bhp_train)\n",
    "hf_w.create_dataset('dt', data = dt_train)\n",
    "hf_w.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bhp_eval.shape)\n",
    "print(dt_eval.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_w = h5py.File(data_dir + case_name + '_e2c_eval' + case_suffix + train_suffix+'_n%d_dt%dday_nt%d_nrun%d.mat'%(n_eval_step, dt, num_t_slt, n_eval_run), 'w')\n",
    "hf_w.create_dataset('state_t', data=state_t_eval)\n",
    "hf_w.create_dataset('state_t1', data=state_t1_eval)\n",
    "hf_w.create_dataset('bhp', data = bhp_eval)\n",
    "hf_w.create_dataset('dt', data = dt_eval)\n",
    "hf_w.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
